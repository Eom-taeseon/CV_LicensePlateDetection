{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3296b081",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from argparse import ArgumentParser\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.autograd import Variable\n",
    "from load_data import *\n",
    "# from module.det_part.detection_head import GaussDistanceLoss\n",
    "import module.det_part.PostProcessing as postP\n",
    "import train_config as train_cfg\n",
    "from model.detection_recognition_pipeline import DetectionRecognitionPipeline, online_distribute_ctc_targets\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33d0e61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_tuple_for_ctc(T_length, lengths):\n",
    "    input_lengths = []\n",
    "    target_lengths = []\n",
    "\n",
    "    for ch in lengths:\n",
    "        input_lengths.append(T_length)\n",
    "        target_lengths.append(ch)\n",
    "\n",
    "    return tuple(input_lengths), tuple(target_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68c00313",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(args, model):\n",
    "    # ===============================【1】DataSet=================================\n",
    "    # val dataset loader\n",
    "    dataset_val = LPDataSet(img_path=train_cfg.test_img_folder_path, txt_path=train_cfg.test_txt_folder_path)\n",
    "    print(\"=>Val dataset total images: % d\" % dataset_val.__len__())\n",
    "    loader_val = DataLoader(dataset_val, num_workers=args.num_workers, batch_size=args.batch_size,\n",
    "                            drop_last=False, shuffle=False, collate_fn=base_lp_collate)\n",
    "    if args.pretrained is not None:\n",
    "        print(\"Load weight from pretrained model ...\")\n",
    "        pretrained_dict = torch.load(args.pretrained)\n",
    "        model_dict = model.state_dict()\n",
    "        pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "        model_dict.update(pretrained_dict)\n",
    "        model.load_state_dict(model_dict)\n",
    "        print(\"=> Load weight successfully.\")\n",
    "    else:\n",
    "        print(\"Please input the model weight!\")\n",
    "        raise ValueError(\"The args pretrained shouldn't be None!\")\n",
    "    model.eval()\n",
    "    result_dict = {}\n",
    "    pred_dict = {}\n",
    "    if args.mode == 0:  # detection only\n",
    "        print(\"The validation mode is: detection only.\")\n",
    "        Tp_all = 0\n",
    "        Fn_all = 0\n",
    "        Fp_all = 0\n",
    "        gauss_all = []\n",
    "        for step, (images, point_label_list, lpchar_label_list, lpchar_length_list, name_list) in enumerate(loader_val):\n",
    "                step += 1\n",
    "                start_time = time.time()\n",
    "                if args.cuda:\n",
    "                    images = images.cuda()\n",
    "                    point_label_list = [label.cuda() for label in point_label_list]\n",
    "                obj_num_list, scores_tensor, coordinates_tensor = model(images, mode1='det_only', mode2='eval')\n",
    "                # ======================= test accuracy of val =====================\n",
    "                start_idx_pred = 0\n",
    "                print(\"obj_num_list\",obj_num_list)\n",
    "                for batch_idx, obj_num_pred in enumerate(obj_num_list):\n",
    "                    print(\"batch_idx, obj_num_pred\",batch_idx, obj_num_pred)\n",
    "                    if obj_num_pred != 0:\n",
    "                        # tensor size(obj_num_pred, 8)\n",
    "                        single_img_coord_preds = coordinates_tensor[start_idx_pred: start_idx_pred + obj_num_pred]\n",
    "                        pred_dict[str(step)] = single_img_coord_preds.cpu().tolist()\n",
    "\n",
    "                        result_dict[str(step)] = point_label_list[batch_idx].cpu().tolist()\n",
    "                        print(\"single_img_coord_preds\",single_img_coord_preds.cpu().tolist())\n",
    "                        print(\"point_label_list\",point_label_list[batch_idx].cpu().tolist())\n",
    "                        start_idx_pred = start_idx_pred + obj_num_pred\n",
    "                        Tp, Fn, Fp, gauss_list = postP.gaussian_eval(single_img_coord_preds, point_label_list[batch_idx])\n",
    "                        Tp_all += Tp\n",
    "                        Fn_all += Fn\n",
    "                        Fp_all += Fp\n",
    "                        gauss_all.extend(gauss_list)\n",
    "                    print(\"batch_idx,Tp_all, Fn_all, Fp_all\", batch_idx,Tp_all, Fn_all, Fp_all)\n",
    "\n",
    "        if Tp_all == 0:\n",
    "            precision = 0.0\n",
    "            recall = 0.0\n",
    "            f1_score = 0.0\n",
    "            mGauss = 0.0\n",
    "        else:\n",
    "            precision = Tp_all * 1.0 / (Tp_all + Fp_all)\n",
    "            recall = Tp_all * 1.0 / (Tp_all + Fn_all)\n",
    "            f1_score = (2 * precision * recall) /(precision + recall)\n",
    "            mGauss = sum(gauss_all) / len(gauss_all)\n",
    "\n",
    "        # ============================= Total Epoch Print =========================\n",
    "        print(\"=> Precision: \", precision)\n",
    "        print(\"=> Recall: \", recall)\n",
    "        print(\"=> F1-score: \", f1_score)\n",
    "        print(\"=> mGauss: %.3f\" % (mGauss * 100))\n",
    "        \n",
    "        with open('result_target_new.json', 'w') as fp:\n",
    "            json.dump(result_dict, fp)\n",
    "        with open('result_pred_new.json', 'w') as fp:\n",
    "            json.dump(pred_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51784948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    print(\"!\")\n",
    "    savedir = os.path.join(cfg.save_parent_folder, str(args.savedir))\n",
    "    print(\"The save file path is: \" + savedir)\n",
    "\n",
    "    if not os.path.exists(savedir):\n",
    "        os.makedirs(savedir)\n",
    "\n",
    "    with open(savedir + '/opts.txt', \"w\") as myfile:\n",
    "        myfile.write(str(args))\n",
    "\n",
    "    # ============================== Load Model ===========================\n",
    "    model = DetectionRecognitionPipeline(input_size=train_cfg.INPUT_SIZE,  # (1024, 1024)\n",
    "                                         det_size=train_cfg.DETECTION_SIZE,   # (512, 512)\n",
    "                                         reg_size=train_cfg.RECOGNITION_SIZE,   # (144, 48)\n",
    "                                         class_num=len(CHARS))  # 68\n",
    "    # =====================================================================\n",
    "    if args.cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "\n",
    "    print(\"========== START TRAINING ===========\")\n",
    "    model = eval(args, model)  # Train decoder\n",
    "    print(\"========== EVALUATE FINISHED ===========\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c291e8ef",
   "metadata": {},
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = ArgumentParser()\n",
    "    parser.add_argument('--cuda', action='store_true', default=True)\n",
    "    parser.add_argument('--mode', type=int, default=0)  # 0 or 1\n",
    "    parser.add_argument('--num_workers', type=int, default=4)\n",
    "    parser.add_argument('--batch_size', type=int, default=1)\n",
    "    parser.add_argument('--steps_interval', type=int, default=50, help='show loss every how many steps')\n",
    "    parser.add_argument('--savedir', default=\"ssnetv2_total_2_11\")\n",
    "    # parser.add_argument('--pretrained', default=\"./weight/weight3_8/model_best.pth\")  # \"./weight/pretrained_original/model_best.pth\"\n",
    "    parser.add_argument('--pretrained', default=\"./weight/SLPNetSave_3/model_best.pth\")  # \"./weight/pretrained_original/model_best.pth\"\n",
    "\n",
    "    main(parser.parse_args())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029aaf32",
   "metadata": {},
   "source": [
    "parser = ArgumentParser()\n",
    "parser.add_argument('--h', action='store_true', default=True)\n",
    "parser.add_argument('--cuda', action='store_true', default=True)\n",
    "parser.add_argument('--mode', type=int, default=0)  # 0 or 1\n",
    "parser.add_argument('--num_workers', type=int, default=4)\n",
    "parser.add_argument('--batch_size', type=int, default=1)\n",
    "parser.add_argument('--steps_interval', type=int, default=50, help='show loss every how many steps')\n",
    "parser.add_argument('--savedir', default=\"ssnetv2_total_2_11\")\n",
    "# parser.add_argument('--pretrained', default=\"./weight/weight3_8/model_best.pth\")  # \"./weight/pretrained_original/model_best.pth\"\n",
    "parser.add_argument('--pretrained', default=\"./weight/SLPNetSave_3/model_best.pth\")  # \"./weight/pretrained_original/model_best.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d9e09be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import easydict\n",
    "\n",
    "args = easydict.EasyDict({\n",
    "    \"h\": \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98465166",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--cuda] [--mode MODE] [--num_workers NUM_WORKERS] [--batch_size BATCH_SIZE]\n",
      "                             [--steps_interval STEPS_INTERVAL] [--savedir SAVEDIR]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\410\\AppData\\Roaming\\jupyter\\runtime\\kernel-8ee8a094-afa2-4f2b-bd11-eadba9776c2c.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "main(parser.parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c6bc32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
